{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3990f1df-2ebf-40f0-9782-3cb25f17d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "863314a9-6d1b-4155-926f-7201403fc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_probability = np.array([[0.8, 0.2], [0.8, 0.2],[0.8, 0.2],[0.825, 0.175],[0.825, 0.175],[0.825,0.175],[0.825, 0.175],[0.825, 0.175],[0.825, 0.175]\n",
    " ,[0.85,0.15 ]])\n",
    "reward_probability = task_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07c78440-22d3-4f30-a3f4-914eefc91cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_model = {0: {15: 12, 14: 5, 16: 3}, 1: {16: 4, 17: 8, 15: 8}, 2: {17: 7, 16: 9, 18: 4}, 3: {18: 5, 17: 9, 19: 6}, 4: {19: 8, 18: 8, 20: 4}, 5: {20: 6, 19: 5, 21: 9}, 6: {22: 5, 21: 6, 20: 9}, 7: {23: 5, 22: 10, 21: 5}, 8: {23: 7, 22: 10, 24: 3}, 9: {24: 8, 25: 5, 23: 7}, 10: {26: 11, 25: 8, 24: 1}, 11: {26: 7, 27: 6, 25: 7}, 12: {27: 8, 26: 5, 28: 7}, 13: {27: 7, 28: 5, 29: 8}, 14: {30: 10, 28: 6, 29: 4}, 15: {29: 7, 30: 3, 31: 10}, 16: {32: 3, 31: 10, 30: 7}, 17: {31: 6, 33: 10, 32: 4}, 18: {34: 7, 33: 7, 32: 6}, 19: {34: 9, 35: 6, 33: 5}, 20: {35: 5, 36: 12, 34: 3}, 21: {37: 11, 36: 6, 35: 3}, 22: {36: 6, 38: 5, 37: 9}, 23: {39: 10, 37: 5, 38: 5}, 24: {38: 6, 39: 7, 40: 7}, 25: {40: 9, 41: 6, 39: 5}, 26: {40: 9, 41: 8, 42: 3}, 27: {42: 8, 41: 7, 43: 5}, 28: {42: 8, 44: 6, 43: 6}, 29: {45: 7, 44: 6, 43: 7}, 30: {45: 7, 46: 7, 44: 6}, 31: {46: 3, 45: 11, 47: 6}, 32: {46: 11, 48: 3, 47: 6}, 33: {49: 6, 48: 8, 47: 6}, 34: {48: 4, 50: 12, 49: 4}, 35: {51: 10, 50: 5, 49: 5}, 36: {52: 9, 50: 4, 51: 7}, 37: {52: 7, 53: 7, 51: 6}, 38: {52: 11, 54: 6, 53: 3}, 39: {54: 8, 55: 6, 53: 6}, 40: {56: 6, 55: 5, 54: 9}, 41: {56: 6, 55: 7, 57: 7}, 42: {56: 6, 57: 9, 58: 5}, 43: {58: 6, 57: 6, 59: 8}, 44: {60: 9, 58: 9, 59: 2}, 45: {60: 11, 61: 3, 59: 6}, 46: {61: 9, 60: 6, 62: 5}, 47: {62: 9, 63: 7, 61: 4}, 48: {63: 5, 62: 9, 64: 6}, 49: {64: 5, 63: 9, 65: 6}, 50: {66: 7, 65: 6, 64: 7}, 51: {65: 6, 66: 8, 67: 6}, 52: {68: 7, 66: 9, 67: 4}, 53: {69: 9, 68: 6, 67: 5}, 54: {69: 5, 70: 7, 68: 8}, 55: {71: 7, 69: 5, 70: 8}, 56: {70: 9, 71: 6, 72: 5}, 57: {71: 10, 73: 5, 72: 5}, 58: {74: 4, 72: 11, 73: 5}, 59: {73: 8, 75: 9, 74: 3}, 60: {75: 8, 74: 8, 76: 4}, 61: {75: 6, 77: 6, 76: 8}, 62: {76: 11, 78: 3, 77: 6}, 63: {78: 7, 79: 8, 77: 5}, 64: {79: 9, 80: 6, 78: 5}, 65: {79: 9, 81: 8, 80: 3}, 66: {81: 8, 82: 8, 80: 4}, 67: {83: 7, 82: 6, 81: 7}, 68: {82: 9, 84: 3, 83: 8}, 69: {83: 8, 85: 7, 84: 5}, 70: {84: 4, 85: 7, 86: 9}, 71: {87: 6, 85: 8, 86: 6}, 72: {86: 4, 88: 7, 87: 9}, 73: {87: 10, 88: 4, 89: 6}, 74: {88: 9, 89: 10, 90: 1}, 75: {90: 9, 91: 6, 89: 5}, 76: {92: 6, 90: 9, 91: 5}, 77: {93: 12, 91: 3, 92: 5}, 78: {92: 6, 94: 6, 93: 8}, 79: {93: 7, 95: 8, 94: 5}, 80: {95: 10, 94: 7, 96: 3}, 81: {95: 6, 97: 9, 96: 5}, 82: {98: 8, 96: 9, 97: 3}, 83: {98: 7, 99: 7, 97: 6}, 84: {99: 7, 98: 5, 100: 8}, 85: {100: 14, 99: 6}, 86: {100: 20}, 87: {100: 20}, 88: {100: 20}, 89: {100: 20}, 90: {100: 20}, 91: {100: 20}, 92: {100: 20}, 93: {100: 20}, 94: {100: 20}, 95: {100: 20}, 96: {100: 20}, 97: {100: 20}, 98: {100: 20}, 99: {100: 20}, 100: {100: 20}}\n",
    "discharge_model = {0: {0: 20}, 1: {0: 20}, 2: {0: 20}, 3: {0: 12, 2: 8}, 4: {2: 14, 0: 6}, 5: {2: 15, 4: 5}, 6: {4: 15, 2: 5}, 7: {4: 13, 6: 7}, 8: {4: 6, 6: 14}, 9: {6: 14, 8: 6}, 10: {8: 16, 6: 4}, 11: {8: 15, 10: 5}, 12: {10: 13, 8: 7}, 13: {10: 16, 12: 4}, 14: {12: 11, 10: 9}, 15: {14: 8, 12: 12}, 16: {14: 15, 12: 5}, 17: {14: 13, 16: 7}, 18: {16: 14, 14: 6}, 19: {16: 13, 18: 7}, 20: {18: 10, 16: 10}, 21: {18: 12, 20: 8}, 22: {20: 15, 18: 5}, 23: {20: 11, 22: 9}, 24: {20: 5, 22: 15}, 25: {22: 14, 24: 6}, 26: {24: 11, 22: 9}, 27: {24: 13, 26: 7}, 28: {24: 12, 26: 8}, 29: {26: 9, 28: 11}, 30: {26: 5, 28: 15}, 31: {28: 14, 30: 6}, 32: {30: 16, 28: 4}, 33: {30: 12, 32: 8}, 34: {32: 15, 30: 5}, 35: {32: 14, 34: 6}, 36: {34: 15, 32: 5}, 37: {34: 13, 36: 7}, 38: {36: 15, 34: 5}, 39: {36: 17, 38: 3}, 40: {36: 6, 38: 14}, 41: {38: 12, 40: 8}, 42: {38: 10, 40: 10}, 43: {42: 7, 40: 13}, 44: {42: 13, 40: 7}, 45: {44: 8, 42: 12}, 46: {44: 15, 42: 5}, 47: {46: 10, 44: 10}, 48: {44: 8, 46: 12}, 49: {46: 12, 48: 8}, 50: {48: 12, 46: 8}, 51: {48: 10, 50: 10}, 52: {48: 8, 50: 12}, 53: {50: 10, 52: 10}, 54: {52: 15, 50: 5}, 55: {54: 11, 52: 9}, 56: {52: 5, 54: 15}, 57: {54: 16, 56: 4}, 58: {56: 16, 54: 4}, 59: {56: 14, 58: 6}, 60: {56: 5, 58: 15}, 61: {60: 7, 58: 13}, 62: {60: 17, 58: 3}, 63: {62: 10, 60: 10}, 64: {62: 12, 60: 8}, 65: {62: 12, 64: 8}, 66: {62: 6, 64: 14}, 67: {66: 11, 64: 9}, 68: {66: 11, 64: 9}, 69: {66: 13, 68: 7}, 70: {68: 13, 66: 7}, 71: {68: 12, 70: 8}, 72: {68: 9, 70: 11}, 73: {72: 8, 70: 12}, 74: {72: 13, 70: 7}, 75: {74: 11, 72: 9}, 76: {74: 10, 72: 10}, 77: {74: 15, 76: 5}, 78: {76: 14, 74: 6}, 79: {76: 13, 78: 7}, 80: {78: 16, 76: 4}, 81: {78: 13, 80: 7}, 82: {80: 13, 78: 7}, 83: {82: 11, 80: 9}, 84: {82: 18, 80: 2}, 85: {82: 16, 84: 4}, 86: {84: 12, 82: 8}, 87: {86: 8, 84: 12}, 88: {84: 10, 86: 10}, 89: {86: 13, 88: 7}, 90: {86: 4, 88: 16}, 91: {88: 13, 90: 7}, 92: {90: 15, 88: 5}, 93: {90: 14, 92: 6}, 94: {92: 15, 90: 5}, 95: {92: 15, 94: 5}, 96: {94: 11, 92: 9}, 97: {94: 13, 96: 7}, 98: {96: 13, 94: 7}, 99: {96: 14, 98: 6}, 100: {96: 7, 98: 13}}\n",
    "go_charge_model = {0: {15: 10, 16: 5, 14: 5}, 1: {15: 7, 16: 7, 17: 6}, 2: {16: 6, 17: 10, 18: 4}, 3: {17: 5, 18: 8, 19: 7}, 4: {18: 5, 20: 6, 19: 9}, 5: {19: 10, 20: 5, 21: 5}, 6: {21: 8, 20: 3, 22: 9}, 7: {22: 5, 21: 7, 23: 8}, 8: {22: 8, 23: 6, 24: 6}, 9: {23: 7, 25: 3, 24: 10}, 10: {24: 7, 26: 8, 25: 5}, 11: {27: 9, 26: 8, 25: 3}, 12: {28: 11, 26: 4, 27: 5}, 13: {29: 10, 27: 8, 28: 2}, 14: {28: 7, 29: 6, 30: 7}, 15: {31: 10, 29: 6, 30: 4}, 16: {30: 9, 31: 6, 32: 5}, 17: {33: 6, 32: 7, 31: 7}, 18: {32: 9, 34: 5, 33: 6}, 19: {33: 7, 35: 5, 34: 8}, 20: {35: 9, 34: 6, 36: 5}, 21: {37: 7, 35: 8, 36: 5}, 22: {36: 8, 37: 8, 38: 4}, 23: {38: 7, 39: 5, 37: 8}, 24: {39: 6, 38: 7, 40: 7}, 25: {39: 7, 41: 6, 40: 7}, 26: {42: 7, 40: 8, 41: 5}, 27: {43: 4, 41: 12, 42: 4}, 28: {44: 8, 42: 6, 43: 6}, 29: {44: 6, 45: 9, 43: 5}, 30: {46: 7, 45: 10, 44: 3}, 31: {46: 7, 47: 7, 45: 6}, 32: {48: 10, 47: 4, 46: 6}, 33: {49: 6, 48: 10, 47: 4}, 34: {48: 6, 49: 10, 50: 4}, 35: {50: 13, 49: 7}, 36: {50: 13, 51: 7}, 37: {50: 9, 52: 9, 51: 2}, 38: {52: 8, 51: 6, 53: 6}, 39: {54: 4, 52: 11, 53: 5}, 40: {54: 8, 53: 4, 55: 8}, 41: {54: 6, 55: 8, 56: 6}, 42: {56: 6, 57: 5, 55: 9}, 43: {56: 4, 57: 10, 58: 6}, 44: {59: 7, 58: 9, 57: 4}, 45: {58: 9, 60: 7, 59: 4}, 46: {60: 6, 59: 7, 61: 7}, 47: {62: 5, 60: 9, 61: 6}, 48: {61: 7, 63: 4, 62: 9}, 49: {63: 5, 64: 10, 62: 5}, 50: {63: 6, 65: 9, 64: 5}, 51: {64: 8, 65: 7, 66: 5}, 52: {65: 4, 67: 7, 66: 9}, 53: {66: 4, 67: 7, 68: 9}, 54: {69: 9, 68: 7, 67: 4}, 55: {68: 7, 69: 8, 70: 5}, 56: {70: 7, 71: 3, 69: 10}, 57: {71: 7, 72: 5, 70: 8}, 58: {71: 6, 73: 9, 72: 5}, 59: {72: 8, 74: 8, 73: 4}, 60: {75: 11, 74: 3, 73: 6}, 61: {76: 7, 74: 9, 75: 4}, 62: {77: 4, 75: 10, 76: 6}, 63: {77: 7, 76: 5, 78: 8}, 64: {79: 6, 77: 11, 78: 3}, 65: {79: 7, 78: 7, 80: 6}, 66: {79: 5, 80: 7, 81: 8}, 67: {81: 9, 80: 5, 82: 6}, 68: {83: 9, 81: 5, 82: 6}, 69: {83: 8, 82: 3, 84: 9}, 70: {84: 8, 85: 6, 83: 6}, 71: {86: 6, 85: 5, 84: 9}, 72: {86: 5, 87: 7, 85: 8}, 73: {88: 7, 87: 5, 86: 8}, 74: {89: 9, 87: 5, 88: 6}, 75: {89: 7, 88: 8, 90: 5}, 76: {89: 6, 90: 5, 91: 9}, 77: {90: 7, 92: 7, 91: 6}, 78: {93: 9, 91: 6, 92: 5}, 79: {92: 8, 93: 9, 94: 3}, 80: {94: 6, 93: 9, 95: 5}, 81: {94: 8, 96: 8, 95: 4}, 82: {97: 9, 95: 7, 96: 4}, 83: {96: 10, 98: 5, 97: 5}, 84: {98: 8, 97: 5, 99: 7}, 85: {99: 13, 98: 7}, 86: {99: 20}, 87: {99: 20}, 88: {99: 20}, 89: {99: 20}, 90: {99: 20}, 91: {99: 20}, 92: {99: 20}, 93: {99: 20}, 94: {99: 20}, 95: {99: 20}, 96: {99: 20}, 97: {99: 20}, 98: {99: 20}, 99: {100: 20}, 100: {100: 20}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47e0fc4c-c7b7-48b5-9149-1a4758b8bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_off_add_to_one(data:list, decimal_place=2):\n",
    "        \"\"\" Step 1: Round each probability to {decimal_place} decimals\n",
    "            Step 2: Compute the difference from 1.\n",
    "        Args:\n",
    "            data (list): _description_\n",
    "        \"\"\"\n",
    "        normalize_data = np.array(data)/np.sum(data)\n",
    "        round_data = np.round(normalize_data, decimal_place)\n",
    "        diff = round((1 - np.sum(round_data)) * 10**(decimal_place))\n",
    "        \n",
    "        sorted_rounded = np.argsort(round_data)\n",
    "        small_diff = np.round(np.power(0.1, decimal_place), decimal_place)\n",
    "        for i in range(abs(diff)):\n",
    "            idx =  sorted_rounded[i % len(round_data)]\n",
    "            if diff > 0:\n",
    "                round_data[idx] += small_diff\n",
    "            else:\n",
    "                round_data[idx] -= small_diff\n",
    "        return round_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4713e1db-c53a-44d3-864e-cbdd511e9370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatteryChargeSchedulingEnvironment:\n",
    "    def __init__(self, charge_model, discharge_model, go_charge_model, task_prob, reward_prob):\n",
    "\n",
    "        self.t_max = 10\n",
    "        \n",
    "        #state\n",
    "        self.t = None\n",
    "        self.battery = None\n",
    "        self.task_present = None\n",
    "        self.charging = None\n",
    "\n",
    "        #action\n",
    "        self.actions = {'gather_reward':0, 'go_charge':1, 'stay_charging':2}\n",
    "        self.action_idx = {0:'gather_reward', 1:'go_charge', 2:'stay_charging'}\n",
    "\n",
    "        # Multi-objective weights (scalarization)\n",
    "        self.w_task = 1.0\n",
    "        self.w_battery = -.5 \n",
    "\n",
    "        #Transistion probability\n",
    "        self.charge_model = charge_model\n",
    "        self.discharge_model = discharge_model\n",
    "        self.go_charge_model = go_charge_model\n",
    "        \n",
    "        self.task_prob = task_prob\n",
    "        self.reward_probability = reward_prob\n",
    "\n",
    "    def get_parameter(self):\n",
    "        return (self.t_max, 101, 2, 2)\n",
    "\n",
    "    def reset(self,t, current_battery:int, is_task_present:int, is_robot_charging:int):\n",
    "        self.t = t\n",
    "        self.battery = current_battery\n",
    "        self.task_present = is_task_present\n",
    "        self.charging = is_robot_charging\n",
    "\n",
    "    def get_state(self):\n",
    "        return (self.t, self.battery, self.task_present, self.charging)\n",
    "\n",
    "    def set_state(self, t, battery, task_present, charging):\n",
    "        self.t = t\n",
    "        self.battery = battery\n",
    "        self.task_present = task_present\n",
    "        self.charging = charging\n",
    "\n",
    "    def get_random_action(self):\n",
    "        if self.charging:\n",
    "            return random.choice([\"gather_reward\", \"stay_charging\"])\n",
    "        else:\n",
    "            return random.choice(list(self.actions.keys()))\n",
    "            \n",
    "    def get_action_idx(self,action):\n",
    "        return self.actions[action]\n",
    "\n",
    "    def get_action_from_idx(self, idx:int):\n",
    "        return self.action_idx[idx]\n",
    "        \n",
    "    def update_time(self, t):\n",
    "        return t + 1\n",
    "\n",
    "    def update_discharging(self, b):\n",
    "        return np.random.choice(list(self.discharge_model[b].keys()), p= round_off_add_to_one(list(self.discharge_model[b])))\n",
    "\n",
    "    def update_charging(self, b):\n",
    "        return np.random.choice(list(self.charge_model[b].keys()), p= round_off_add_to_one(list(self.charge_model[b])))\n",
    "\n",
    "    def update_go_charging(self, b):\n",
    "        return np.random.choice(list(self.go_charge_model[b].keys()), p= round_off_add_to_one(list(self.go_charge_model[b])))\n",
    "\n",
    "    def update_task(self, t):\n",
    "        return 1 if random.random() < self.task_prob[self.t][0] else 0\n",
    "        \n",
    "    def step(self, action):\n",
    "        rew = 0\n",
    "        battery_cost = 0\n",
    "        is_charging = 0\n",
    "        is_task_present = 0\n",
    "        done = False\n",
    "\n",
    "        next_battery = None\n",
    "        \n",
    "        if action == 'gather_reward':\n",
    "            next_battery = self.update_discharging(self.battery)\n",
    "            next_charging = 0\n",
    "            is_task_present = self.update_task(self.t)\n",
    "            rew = 1 if is_task_present else 0\n",
    "        elif action == 'go_charge':\n",
    "            next_battery = self.update_go_charging(self.battery)\n",
    "            next_charging = 1\n",
    "        elif action == 'stay_charging':\n",
    "            next_battery = self.update_charging(self.battery)\n",
    "            next_charging = 1\n",
    "\n",
    "        next_t = self.update_time(self.t)\n",
    "        \n",
    "        if next_battery < 40:\n",
    "            battery_cost = 1\n",
    "            \n",
    "        scalar_reward = self.w_task * rew + self.w_battery * battery_cost\n",
    "\n",
    "        if (next_t + 1) >= self.t_max:\n",
    "            done = True\n",
    "            \n",
    "        return (next_t, next_battery, is_task_present, is_charging), scalar_reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9f970768-c439-4ca5-a907-612d7565013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "        (num_timesteps, battery_levels, task_states, charging_states) = self.env.get_parameter()\n",
    "        \n",
    "        self.Q = np.zeros((num_timesteps, battery_levels, task_states, charging_states, len(self.env.actions)))\n",
    "    \n",
    "        self.alpha = 0.01            # learning rate\n",
    "        self.gamma = 0.9            # discount factor\n",
    "        self.epsilon_min = 0.001\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon = 0.1          # exploration\n",
    "        self.num_episodes = 10000\n",
    "        self.num_timesteps = 100\n",
    "\n",
    "        self.max_reward = []\n",
    "        \n",
    "    def training(self):\n",
    "        for ep in range(self.num_episodes):\n",
    "            env.reset(0, 38, 1, 1)\n",
    "            state = env.get_state()  # initial state\n",
    "            total_reward = 0\n",
    "            count = 0\n",
    "            self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "            for _ in range(self.num_timesteps):\n",
    "                t, battery, task, charging = state\n",
    "                \n",
    "                action = self.env.get_action_from_idx(np.argmax(self.Q[t, battery, task, charging]))\n",
    "        \n",
    "                # Îµ-greedy action selection\n",
    "                if random.random() < self.epsilon:\n",
    "                    action = self.env.get_random_action()\n",
    "\n",
    "                # Step environment\n",
    "                next_state, reward, done = self.env.step(action)\n",
    "                nt, nbattery, ntask, nch = next_state\n",
    "\n",
    "                total_reward += reward\n",
    "\n",
    "                action_idx = self.env.get_action_idx(action)\n",
    "                \n",
    "                # Q-learning update\n",
    "                td_error = (reward + self.gamma * np.max(self.Q[nt, nbattery, ntask, nch]) -\n",
    "                    self.Q[t, battery, task, charging, action_idx])\n",
    "\n",
    "                \n",
    "                self.Q[t, battery, task, charging, action_idx] += self.alpha * td_error\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "                self.env.set_state(nt, nbattery, ntask, nch)\n",
    "            self.max_reward.append(total_reward)\n",
    "                \n",
    "    def policy_summary():\n",
    "        policy = np.argmax(Q, axis=-1)\n",
    "        print(\"Learned policy shape:\", policy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5e59cb7f-5802-428b-bec9-d369e7db4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BatteryChargeSchedulingEnvironment(charge_model=charging_model, \n",
    "                                         discharge_model=discharge_model,\n",
    "                                         go_charge_model=go_charge_model, \n",
    "                                         task_prob=task_probability, \n",
    "                                         reward_prob= reward_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ee9723b6-1888-44be-8a29-cc376d677ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql = QLearning(env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "dbb82aea-0934-4a5d-a95b-b2b1328cb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f0d3d349-1bcb-4a81-8d93-2623ece47ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ba9b3056-8155-49cb-a805-4f66faeed609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.8448)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "93822d2c-bfaf-45f9-9c07-58dcbce0569a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31439456, -0.14444447, -0.11047202])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.Q[0, 38, 1, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed8d36-4f47-4f4b-8c80-044a2ed90df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
